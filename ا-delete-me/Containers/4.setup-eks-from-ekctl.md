# âš™ï¸ **Setup Amazon EKS Using `eksctl`**

> Quickly create and manage Kubernetes clusters on AWS with a single CLI command using `eksctl`.

---

## ðŸš€ **Why `eksctl`?**

`eksctl` is the **official CLI tool** for EKS. It simplifies:

- ðŸ§± Creating EKS clusters and VPCs
- ðŸ‘· Adding managed node groups
- âš™ï¸ Updating `kubeconfig`
- ðŸ§© Creating Fargate profiles
- ðŸ”„ Managing lifecycle of clusters and resources

---

## âœ… **Prerequisites**

| Requirement            | Description                                                             |
| ---------------------- | ----------------------------------------------------------------------- |
| ðŸ§‘â€ðŸ’¼ **AWS Account**  | Active account with access to IAM, EC2, VPC, and EKS services           |
| ðŸ” **IAM Permissions** | User must have permissions to create IAM roles, VPCs, and EKS resources |
| ðŸ§° **Tools Installed** | `kubectl`, `aws-cli`, and `eksctl` installed and configured             |

---

## ðŸ“¦ **Install `eksctl`**

### ðŸ–¥ï¸ On macOS (Homebrew)

```bash
brew tap weaveworks/tap
brew install weaveworks/tap/eksctl
```

### ðŸ§ On Linux

```bash
curl --silent --location "https://github.com/weaveworks/eksctl/releases/download/0.141.0/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
sudo mv /tmp/eksctl /usr/local/bin
```

### ðŸ” Verify Installation

```bash
eksctl version
```

---

## ðŸ› ï¸ **Step-by-Step EKS Cluster Setup**

### 1ï¸âƒ£ **Create an EKS Cluster with Managed Nodes**

```bash
eksctl create cluster \
--name my-cluster \
--region us-west-2 \
--nodegroup-name linux-nodes \
--node-type t3.medium \
--nodes 3 \
--nodes-min 1 \
--nodes-max 4 \
--managed
```

ðŸ”Ž **Parameters Explained**:

- `--name`: Cluster name
- `--region`: AWS region
- `--nodegroup-name`: Name for the EC2 node group
- `--node-type`: EC2 instance type
- `--nodes`: Desired number of nodes
- `--managed`: Creates an **EKS-managed** node group

> â³ Cluster creation takes \~15 minutes. It includes VPC, subnets, security groups, and IAM roles.

---

### 2ï¸âƒ£ **Configure `kubectl`**

Update the `kubeconfig` to connect your CLI with the newly created EKS cluster:

```bash
aws eks --region us-west-2 update-kubeconfig --name my-cluster
kubectl get nodes
```

âœ… You should see your EC2 worker nodes listed.

---

### 3ï¸âƒ£ **(Optional) Create a Fargate Profile**

To use **serverless pods** in EKS:

```bash
eksctl create fargateprofile \
--cluster my-cluster \
--name my-fargate-profile \
--namespace default
```

ðŸ“Œ Fargate profiles run pods in specific namespaces or with labels on AWS Fargate.

---

### 4ï¸âƒ£ **Deploy a Sample App**

#### âœï¸ Deployment YAML

Save this as `deployment.yaml`:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sample-deployment
spec:
  replicas: 2
  selector:
    matchLabels:
      app: sample-app
  template:
    metadata:
      labels:
        app: sample-app
    spec:
      containers:
        - name: nginx
          image: nginx
          ports:
            - containerPort: 80
```

#### ðŸš€ Apply It

```bash
kubectl apply -f deployment.yaml
kubectl get pods
```

âœ… You should see 2 NGINX pods running.

---

### 5ï¸âƒ£ **(Optional) Configure Cluster Autoscaler**

#### ðŸ“¥ Download Manifest

```bash
curl -O https://raw.githubusercontent.com/kubernetes/autoscaler/master/cluster-autoscaler/cloudprovider/aws/examples/cluster-autoscaler-one-asg.yaml
```

#### ðŸ“ Edit the File

- Replace `YOUR CLUSTER NAME` with `my-cluster`
- Add region:

```yaml
- --aws-region=us-west-2
```

#### ðŸ“¦ Deploy

```bash
kubectl apply -f cluster-autoscaler-one-asg.yaml
```

#### ðŸ”„ Update Image (Match Kubernetes version)

```bash
kubectl set image deployment/cluster-autoscaler \
-n kube-system cluster-autoscaler=k8s.gcr.io/cluster-autoscaler:v1.21.0
```

#### âœ… Verify Deployment

```bash
kubectl get pods -n kube-system -l "app.kubernetes.io/name=cluster-autoscaler"
```

---

## âš™ï¸ **Additional Configurations**

### ðŸŒ Set Up Ingress Controller

Use AWS ALB Controller:

```bash
kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/main/docs/examples/alb-ingress-controller.yaml
```

> You can use NGINX Ingress Controller or AWS Load Balancer Controller based on your architecture.

---

### ðŸ’¾ Configure Persistent Storage

- Define **PersistentVolume (PV)** and **PersistentVolumeClaim (PVC)**
- Use **gp2/gp3** as `storageClassName`
- Mount inside your Pods via `volumeMounts`

---

## ðŸ§  Summary

| Task                     | Tool      | Command / Outcome                            |
| ------------------------ | --------- | -------------------------------------------- |
| Create EKS Cluster       | `eksctl`  | Cluster + VPC + Node Group (one-shot setup)  |
| Connect via CLI          | `aws-cli` | Update kubeconfig to talk to your cluster    |
| Deploy Apps              | `kubectl` | Deploy workloads to EC2 or Fargate           |
| Autoscaling              | `kubectl` | Use Cluster Autoscaler (optional but useful) |
| Ingress & Load Balancing | Ingress   | Deploy ALB or NGINX Controller               |
| Storage                  | PV + PVC  | Use EBS (EC2) or EFS (Fargate)               |

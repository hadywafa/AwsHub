# ğŸ” **AWS Lambda â€“ Event Source Mapping (SQS, Kinesis, DynamoDB)**

> **Event Source Mapping** (ESM) is the powerful engine that connects AWS Lambda to streaming or queuing services like **SQS**, **SQS FIFO**, **Kinesis**, and **DynamoDB Streams**.
>
> It acts as an **internal poller** that reads events from the source and invokes your function **synchronously with event batches**, all without you managing polling logic.

---

## ğŸ¯ **What is Event Source Mapping (ESM)?**

> Event Source Mapping is a Lambda component that **polls** an event source (queue or stream), **buffers messages**, and **triggers Lambda** with a batch.

Common event sources:

- ğŸ”„ **SQS & SQS FIFO**
- ğŸ“Š **Kinesis Data Streams**
- ğŸ”— **DynamoDB Streams**

---

<div style="text-align:center;">
  <img src="images/lambda-event-source-mapping.png" alt="Event Source Mapping - General" style="border-radius: 10px; width: 50%;" />
</div>

---

## ğŸ”· **How Lambda + Streams Work (Kinesis & DynamoDB)**

Streams are **sharded**, and Lambda uses **one iterator per shard** to read and process records.

<div style="text-align:center;">
  <img src="images/lambda-event-source-mapping-how-it-works.png" alt="Kinesis Shard Record Processing" style="border-radius: 10px; width: 90%;" />
</div>

---

### ğŸ” Flow

1. Lambda internally polls each shard
2. Events are **batched by partition key**
3. Batches are processed in **order within each shard**
4. **Parallelization** allows up to **10 batches per shard** (configurable)

### ğŸ“Œ Key Characteristics

| Feature                    | Details                                                                |
| -------------------------- | ---------------------------------------------------------------------- |
| âœ… **In-order processing** | Guaranteed within a partition/shard                                    |
| ğŸš€ **Parallel batches**    | Up to 10 simultaneous batches per shard (`parallelizationFactor = 10`) |
| ğŸ• **Batch Window**        | Delay batch delivery to accumulate more records                        |
| ğŸ” **Retry on failure**    | Entire batch is retried until success or expiry                        |
| âš ï¸ **Blocking behavior**   | Errors **pause shard** until issue is resolved                         |

> ğŸ§  Stream records are **not deleted** after processing â€” they remain for other consumers.

---

## ğŸ”· **How Lambda + SQS Works**

SQS queues are fully **managed and persistent**, making them ideal for decoupling microservices.

<div style="text-align:center;">
  <img src="images/lambda-sqs-event-source-mapping.png" alt="Lambda SQS Event Source Mapping" style="border-radius: 10px; width: 75%;" />
</div>

---

### ğŸ” Flow

1. Lambda long-polls SQS
2. Messages are returned in batches (size = 1â€“10)
3. Lambda invokes your function with the batch
4. Success = delete from queue
5. Failure = re-queued after **visibility timeout**

### ğŸ“Œ Key Characteristics

| Feature               | Standard Queue                 | FIFO Queue                            |
| --------------------- | ------------------------------ | ------------------------------------- |
| âœ… Delivery model     | At-least-once                  | Exactly-once within message group     |
| ğŸ”„ Message order      | No guarantee                   | Strict order by `MessageGroupId`      |
| ğŸ§  Scaling            | Up to 1,000 concurrent batches | Scales to active message groups       |
| âŒ› Visibility timeout | Must be 6Ã— your Lambda timeout | Same best practice applies            |
| âš ï¸ DLQ Location       | Must be on SQS queue           | DLQ not supported directly via Lambda |

---

## ğŸ“ˆ **Scaling Behavior â€“ All Event Sources**

| Source Type          | Scaling Strategy                                                                    |
| -------------------- | ----------------------------------------------------------------------------------- |
| **Kinesis**          | 1 Lambda per shard â†’ up to 10 batches/shard via parallelization                     |
| **DynamoDB Streams** | Same as Kinesis                                                                     |
| **SQS Standard**     | Adds up to 60 Lambda instances per minute â†’ up to 1,000 concurrent batch processors |
| **SQS FIFO**         | One Lambda per active **MessageGroupId**                                            |

---

## ğŸš¨ **Error Handling and Retries**

### ğŸ” **Streams (Kinesis/DynamoDB)**

| Scenario              | Behavior                                                |
| --------------------- | ------------------------------------------------------- |
| âŒ Lambda fails       | Entire batch retried (same records)                     |
| â— Order enforced     | Shard is **blocked** until error is resolved            |
| ğŸ”§ Options            | Use **bisect batch on error**, maxRetry, discard policy |
| ğŸ§ª Dead-letter option | Use **Lambda Destinations** for discarded events        |

### ğŸ” **SQS (Standard/FIFO)**

| Scenario         | Behavior                                          |
| ---------------- | ------------------------------------------------- |
| âŒ Lambda fails  | Messages return to queue after visibility timeout |
| â™»ï¸ Partial retry | Only failed messages are retried                  |
| ğŸ“¦ Reordering    | Standard queue may reorder on retry               |
| ğŸ§ª DLQ           | Must be attached to **SQS queue**                 |

---

## ğŸ”§ **Tuning Parameters: SQS vs Streams**

| Feature                | SQS                    | Kinesis / DynamoDB Streams         |
| ---------------------- | ---------------------- | ---------------------------------- |
| **Batch size**         | 1â€“10                   | 1â€“10,000                           |
| **Batch window**       | Not supported          | âœ… Helps buffer low-traffic shards |
| **Visibility timeout** | Queue-level setting    | Not required                       |
| **Parallelization**    | Scales with queue load | Configure `parallelizationFactor`  |
| **Ordering**           | FIFO only              | Per shard & per partition key      |

---

## ğŸ§  Best Practices Summary

| âœ… Practice                                 | ğŸ’¡ Why Itâ€™s Important                             |
| ------------------------------------------- | ------------------------------------------------- |
| Set visibility timeout = Lambda timeout Ã— 6 | Prevent premature retries in SQS                  |
| Use DLQ for SQS, not Lambda                 | Ensures persistent failure recovery               |
| Enable batch window (streams)               | Efficient processing during low throughput        |
| Enable bisect batch on error                | Helps isolate failed records in stream processing |
| Monitor iterator age (streams)              | Alerts if batch processing lags behind            |
| Design multiple MessageGroupIds             | For FIFO: enables parallel processing             |

---

## ğŸ§¾ Final Summary: When to Use What?

| Scenario                                   | Recommended Source         |
| ------------------------------------------ | -------------------------- |
| You need in-order processing               | Kinesis, FIFO SQS          |
| You want massive scale                     | SQS Standard               |
| You need multiple consumers for same data  | Kinesis or DynamoDB Stream |
| You want retry+DLQ with persistent storage | SQS                        |
| You want high throughput, low latency      | Streams with batching      |

---

## ğŸ“Œ Conclusion

**Event Source Mapping** is the backbone of integrating Lambda with queues and streams.

It lets you build **scalable**, **reliable**, and **event-driven applications** without worrying about polling, concurrency, or retries.

Use:

- âœ… **Kinesis/DynamoDB** for high-throughput, shard-based ordering
- âœ… **SQS Standard** for fan-out microservices
- âœ… **SQS FIFO** for strict order-sensitive workflows
